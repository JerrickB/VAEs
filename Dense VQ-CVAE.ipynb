{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.conv_learner import *\n",
    "from utils.blocks import *\n",
    "import pdb\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark=True\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../data/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"bs\":16,\n",
    "         \"sz\": 28,\n",
    "         \"t_pc\": 1,\n",
    "         \"epochs\": 7,\n",
    "         \"lr\": 2e-3,\n",
    "         \"n_lat\": 24,\n",
    "         \"n_emb\": 256,\n",
    "         \"lat_chan\": 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH/\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = df[:int(len(df)*params[\"t_pc\"])].drop(\"label\", axis =1)\n",
    "imgs = imgs/255.0\n",
    "val_idxs = get_cv_idxs(len(imgs))\n",
    "((x_val, x_train),) = split_by_idx(val_idxs, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.values.reshape(-1,1,params[\"sz\"],params[\"sz\"])\n",
    "x_train = x_train.values.reshape(-1,1,params[\"sz\"],params[\"sz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ImageClassifierData.from_arrays(PATH, (x_train, x_train), (x_val, x_val), bs=params[\"bs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/nakosung/VQ-VAE/blob/master/model.py\n",
    "#https://github.com/zalandoresearch/pytorch-vq-vae/blob/master/vq-vae.ipynb\n",
    "\n",
    "class VectorQuant(nn.Module):\n",
    "    def __init__(self, num_emb, emb_dim, comm_cost):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_emb = num_emb\n",
    "        self.emb = nn.Embedding(self.num_emb, self.emb_dim)\n",
    "        self.emb.weight.data.uniform_(-1/self.num_emb, 1/self.num_emb)\n",
    "        self.comm_cost = comm_cost\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,3,1).contiguous()\n",
    "        x_sz = x.shape\n",
    "        \n",
    "        flat = x.view(-1, self.emb_dim)\n",
    "        \n",
    "        dist = (torch.sum(flat**2, dim=1, keepdim=True) + torch.sum(self.emb.weight**2, dim=1)\n",
    "            - 2 * torch.matmul(flat, self.emb.weight.t()))\n",
    "        \n",
    "        enc_idxs = torch.argmin(dist, dim=1).unsqueeze(1)\n",
    "        encs = torch.zeros(enc_idxs.shape[0], self.num_emb).cuda()\n",
    "        encs.scatter_(1,enc_idxs,1)\n",
    "        \n",
    "        quant = torch.matmul(encs, self.emb.weight).view(x_sz)\n",
    "        \n",
    "        e_lat_loss = torch.mean((quant.detach()-x)**2)\n",
    "        q_lat_loss = torch.mean((quant-x.detach())**2)\n",
    "        loss = q_lat_loss + self.comm_cost * e_lat_loss\n",
    "        \n",
    "        quant = x + (quant - x).detach()\n",
    "        avg_probs = torch.mean(encs, dim =0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        \n",
    "        return quant.permute(0,3,1,2).contiguous(), loss, perplexity, encs\n",
    "\n",
    "class StdConv(nn.Module):\n",
    "    def __init__(self, nin, nout, stri=2, kern=4, pad=1, drop=0.1, relu=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(nin, nout, kernel_size=kern, stride=stri, padding=pad,bias=False)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.relu = relu\n",
    "    def forward(self, x):\n",
    "        if self.relu:\n",
    "            return self.drop(self.bn(F.relu(self.conv(x))))\n",
    "        else:\n",
    "            return self.drop(self.bn(self.conv(x)))\n",
    "        \n",
    "class StdUpsample(nn.Module):\n",
    "    def __init__(self, nin, nout,kern=2,stri=2, pad=0,drop=None):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(nin, nout, kern, stri, padding=pad)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        if drop: self.drop = nn.Dropout(drop)\n",
    "        else: self.drop = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.drop:\n",
    "            return self.drop(self.bn(F.relu(self.conv(x))))\n",
    "        else:\n",
    "            return self.bn(F.relu(self.conv(x)))\n",
    "        \n",
    "class StdLinear(nn.Module):\n",
    "    def __init__(self, nin, nout, relu=True):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(nin, nout)\n",
    "        self.relu = relu\n",
    "    def forward(self, x):\n",
    "        if self.relu: return F.relu(self.lin(x))\n",
    "        return self.lin(x)\n",
    "    \n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, nin, nout, kern=1, stri=1, pad=0):\n",
    "        super().__init__()\n",
    "        self.conv1 = StdConv(nin, nin, stri, kern, pad)\n",
    "        self.conv2 = StdConv(nin, nin, stri, kern, pad)\n",
    "        self.conv3 = StdConv(nin*2, nin, stri, kern, pad)\n",
    "        self.conv4 = StdConv(nin*3, nin, stri, kern, pad)\n",
    "        self.conv5 = StdConv(nin*4, nout, stri, kern, pad)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        o1 = self.conv1(x)\n",
    "        o2 = self.conv2(o1)\n",
    "        o2c = torch.cat([o2,o1], dim=1)\n",
    "        o3 = self.conv3(o2c)\n",
    "        o3c = torch.cat([o2c,o3], dim=1)\n",
    "        o4 = self.conv4(o3c)\n",
    "        o4c = torch.cat([o3c, o4], dim=1)\n",
    "        o5 = self.conv5(o4c)\n",
    "        return o5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VQ_CVAE(nn.Module):\n",
    "    def __init__(self, n_latent, n_emb=512, lat_chan=64, commit_coef=.25, vae=True):\n",
    "        super().__init__()\n",
    "        self.vae = vae\n",
    "        self.n_latent = n_latent\n",
    "        self.lat_chan = l_c = lat_chan\n",
    "        self.z_dim = 28//2**2\n",
    "        self.h_dim = self.lat_chan * self.z_dim**2\n",
    "        \n",
    "        \n",
    "        #encoder\n",
    "        self.conv1 = StdConv(1 ,l_c//4)\n",
    "        self.ddense1 = DenseBlock(l_c//4,l_c//4)\n",
    "        self.conv2 = StdConv(l_c//4, l_c//2, 1,1,0)\n",
    "        self.conv3 = StdConv(l_c//2, self.lat_chan)\n",
    "        \n",
    "        self.emb = VectorQuant(n_emb, self.lat_chan, commit_coef)\n",
    "        \n",
    "        #q\n",
    "        self.q_mean = StdLinear(self.h_dim, self.n_latent)\n",
    "        self.q_logvar = StdLinear(self.h_dim, self.n_latent)\n",
    "        self.q_project = StdLinear(n_latent, self.h_dim, False)\n",
    "        \n",
    "        #decoder\n",
    "        if self.vae:\n",
    "            self.upconv0 = StdUpsample(self.lat_chan*2,self.lat_chan,1,1)\n",
    "        self.upconv1 = StdUpsample(self.lat_chan,l_c//2,drop=.1)\n",
    "        self.udense1 = DenseBlock(l_c//2,l_c//2)\n",
    "        self.upconv2 = StdUpsample(l_c//2, l_c//4, 1,1,drop=.1)\n",
    "        self.upconv3 = StdUpsample(l_c//4, 1)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.conv1(x)\n",
    "        self.xc1 = x\n",
    "        x = self.ddense1(x)\n",
    "        x = self.conv2(x)\n",
    "        self.xc2 = x\n",
    "        x = self.conv3(x)\n",
    "        self.xc3 = x\n",
    "        return x.view(x.size(0),-1)\n",
    "    \n",
    "    def z(self, flattened):\n",
    "        self.mean, self.logvar = self.q_mean(flattened), self.q_logvar(flattened)\n",
    "        std = self.logvar.mul(.5).exp_()\n",
    "        eps = Variable(torch.randn(std.size())).cuda()\n",
    "        return eps.mul(std).add_(self.mean)\n",
    "    \n",
    "    def decode(self, z, train=True):\n",
    "        if train: torch.cat([z,self.xc3], dim=1)\n",
    "        z = self.upconv1(z)\n",
    "        z = self.udense1(z)\n",
    "        if train: torch.cat([z,self.xc2], dim=1)\n",
    "        z = self.upconv2(z)\n",
    "        if train: torch.cat([z,self.xc1], dim=1)\n",
    "        z = self.upconv3(z)\n",
    "        return z        \n",
    "\n",
    "    def forward(self, x):\n",
    "        flattened = self.encode(x)\n",
    "        if self.vae:\n",
    "            z = self.z(flattened)\n",
    "            z = self.q_project(z).view(-1, self.lat_chan, self.z_dim, self.z_dim)\n",
    "            quant, loss, perp, _ = self.emb(z)\n",
    "            quant = torch.cat([quant, z], dim=1)\n",
    "            quant = self.upconv0(quant)\n",
    "            decoded = self.decode(quant)\n",
    "            return decoded, (loss, perp), (self.mean, self.logvar)\n",
    "        else:\n",
    "            quant, loss, perp, _ = self.emb(flattened.view(-1, self.lat_chan, self.z_dim, self.z_dim))\n",
    "            decoded = self.decode(quant)\n",
    "            return decoded, loss, perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_stats(ep_vals, epoch, values, decimals=6):\n",
    "    ep_vals[epoch]=list(np.round(values, decimals))\n",
    "    return ep_vals\n",
    "\n",
    "def print_stats(epoch, values, decimals=3):\n",
    "    layout = \"{!s:^10}\" + \" {!s:10}\" * len(values)\n",
    "    values = [epoch] + list(np.round(values, decimals))\n",
    "    print(layout.format(*values))\n",
    "trains = collections.OrderedDict()\n",
    "run=0\n",
    "names = [\"iters\",\"recon\",\"perp\",\"kl\",\"vq_loss\"]\n",
    "layout = \"{!s:10} \" * len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'kern'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8254e8df8aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_lat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_lat\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_lat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVQ_CVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_lat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_chan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-802d9b320d54>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_latent, n_emb, lat_chan, commit_coef, vae)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStdConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0ml_c\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mddense1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_c\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml_c\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStdConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_c\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_c\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'kern'"
     ]
    }
   ],
   "source": [
    "lr = start_lr = params[\"lr\"]\n",
    "epochs = params[\"epochs\"] = 7\n",
    "iters = params[\"num_train_updates\"] = len(md.trn_dl)\n",
    "n_lat = params[\"n_lat\"]\n",
    "n_emb = params[\"n_emb\"] = 256\n",
    "lat_chan = params[\"lat_chan\"] = 64\n",
    "for n_lat in [128,64,10]:\n",
    "    params[\"n_lat\"] = n_lat\n",
    "    net = VQ_CVAE(n_lat, n_emb, lat_chan, commit_coef=.2, vae=True).cuda()\n",
    "    net.train()\n",
    "    train_recon = []\n",
    "    train_perp  = []\n",
    "    train_kl = []\n",
    "    train_vq_list = []\n",
    "    val_recon_error = []\n",
    "    val_perp = []\n",
    "    ep_vals = collections.OrderedDict()\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=2e-5, amsgrad=True)\n",
    "    print(list(params.items())[3:])\n",
    "    print(layout.format(*names))\n",
    "    for e in range(epochs):\n",
    "        for i in range(iters):\n",
    "            net.train()\n",
    "            data, _ = next(iter(md.trn_dl))\n",
    "            optimizer.zero_grad()\n",
    "            if net.vae:\n",
    "                data_recon, (vq_loss, perplexity), (mean, logvar) = net(data)\n",
    "                kl = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "                train_vq_list.append(vq_loss.item())\n",
    "                train_kl.append(kl.item())\n",
    "                vq_loss += kl\n",
    "            else:\n",
    "                data_recon, vq_loss, perplexity = net(data)\n",
    "\n",
    "            recon_error = nn.MSELoss(reduction=\"sum\")(data_recon, data)\n",
    "\n",
    "            loss = recon_error + vq_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            val_dat, _ = next(iter(md.val_dl))\n",
    "            net.eval()\n",
    "            if net.vae: val_recon, (val_vq_loss, perp), _ = net(data)\n",
    "            else: val_recon, val_vq_loss, perp = net(val_dat)\n",
    "\n",
    "            val_error = nn.MSELoss(reduction=\"sum\")(val_recon, val_dat)\n",
    "\n",
    "            train_recon.append(recon_error.item())\n",
    "            train_perp.append(perplexity.item())\n",
    "            val_recon_error.append(val_error.item())\n",
    "            val_perp.append(perp.item())\n",
    "            if (i+1) % (params[\"num_train_updates\"]/5) == 0:\n",
    "                vals = [np.round(np.mean(train_recon[-100:]),3), np.round(np.mean(train_perp[-100:]),3), np.round(np.mean(train_kl[-100:]),3),np.round(np.mean(train_vq_list[-100:]),3)]\n",
    "                print_stats(f\"{e+1} / {i+1}\", vals)\n",
    "        \n",
    "        ep_vals = append_stats(ep_vals, e, vals)\n",
    "\n",
    "    run += 1\n",
    "    trains[run] = [list(params.items())[3:], ep_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1,\n",
       "              [[('epochs', 5),\n",
       "                ('lr', 0.002),\n",
       "                ('n_lat', 49),\n",
       "                ('n_emb', 256),\n",
       "                ('lat_chan', 64),\n",
       "                ('num_train_updates', 2100)],\n",
       "               OrderedDict([(0, [688.257, 116.346, 78.635, 0.511]),\n",
       "                            (1, [653.765, 124.569, 95.743, 0.613]),\n",
       "                            (2, [619.472, 130.098, 112.873, 0.735]),\n",
       "                            (3, [592.716, 134.527, 112.788, 0.851]),\n",
       "                            (4, [584.979, 138.973, 122.461, 0.968])])]),\n",
       "             (2,\n",
       "              [[('epochs', 7),\n",
       "                ('lr', 0.002),\n",
       "                ('n_lat', 49),\n",
       "                ('n_emb', 256),\n",
       "                ('lat_chan', 64),\n",
       "                ('num_train_updates', 2100)],\n",
       "               OrderedDict([(0, [649.621, 92.794, 111.926, 0.475]),\n",
       "                            (1, [611.624, 106.662, 123.04, 0.532]),\n",
       "                            (2, [596.895, 116.293, 129.654, 0.59]),\n",
       "                            (3, [582.483, 122.492, 132.621, 0.648]),\n",
       "                            (4, [575.624, 126.537, 138.722, 0.703]),\n",
       "                            (5, [562.131, 129.576, 144.879, 0.759]),\n",
       "                            (6, [554.364, 132.185, 142.1, 0.811])])]),\n",
       "             (3,\n",
       "              [[('epochs', 7),\n",
       "                ('lr', 0.002),\n",
       "                ('n_lat', 49),\n",
       "                ('n_emb', 256),\n",
       "                ('lat_chan', 64),\n",
       "                ('num_train_updates', 2100)],\n",
       "               OrderedDict([(0, [647.043, 100.428, 109.245, 0.507]),\n",
       "                            (1, [608.784, 115.385, 118.27, 0.6]),\n",
       "                            (2, [599.722, 127.044, 122.175, 0.679]),\n",
       "                            (3, [591.449, 133.486, 126.483, 0.743]),\n",
       "                            (4, [574.357, 138.672, 126.417, 0.818]),\n",
       "                            (5, [587.659, 142.072, 132.506, 0.887]),\n",
       "                            (6, [567.052, 145.488, 134.213, 0.958])])]),\n",
       "             (4,\n",
       "              [[('epochs', 7),\n",
       "                ('lr', 0.002),\n",
       "                ('n_lat', 49),\n",
       "                ('n_emb', 256),\n",
       "                ('lat_chan', 64),\n",
       "                ('num_train_updates', 2100)],\n",
       "               OrderedDict([(0, [733.559, 171.346, 56.144, 0.42]),\n",
       "                            (1, [718.744, 196.692, 60.238, 0.416]),\n",
       "                            (2, [695.168, 212.548, 76.753, 0.47]),\n",
       "                            (3, [689.073, 210.689, 79.667, 0.494]),\n",
       "                            (4, [680.239, 213.043, 82.785, 0.511]),\n",
       "                            (5, [665.343, 210.576, 90.899, 0.553]),\n",
       "                            (6, [643.651, 212.491, 99.114, 0.601])])])])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x, _ = next(iter(md.val_dl))\n",
    "# x = V(x)\n",
    "# plt.imshow(x[3][0,:,:])\n",
    "# im,_,_ = net(x)\n",
    "# plt.imshow(im.data[2].cpu().numpy().reshape(28,28)*255.)\n",
    "# net.emb(net.encode(x).view(-1, 64, net.z_dim, net.z_dim))[1].shape\n",
    "# print(net.encode(x).shape); net.emb.emb.weight.shape\n",
    "# ep_vals\n",
    "trains\n",
    "# %debug\n",
    "# list(md.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = iter(md.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate(bs=params[\"bs\"],mode=None):\n",
    "    if mode == 0:\n",
    "        vx = torch.FloatTensor([np.random.normal(0, 1, params[\"sz\"]**2) for _ in range(bs)]).cuda()\n",
    "        vx = V(vx).view(-1,1,params[\"sz\"],params[\"sz\"])\n",
    "        net.eval()\n",
    "#         vx = Variable(torch.randn(bs,params[\"sz\"]**2,dtype=torch.float, device=\"cuda\")).view(-1,1,params[\"sz\"],params[\"sz\"])\n",
    "        return net(vx)\n",
    "    else:\n",
    "#         vx = torch.FloatTensor([np.random.normal(0, 1, params[\"sz\"]**2) for _ in range(bs)]).cuda()\n",
    "#         vx = V(vx).view(-1,1,params[\"sz\"],params[\"sz\"])\n",
    "        vx = Variable(torch.randn(bs, 3136)).view(-1, 64, net.z_dim, net.z_dim).cuda()\n",
    "        net.eval()\n",
    "        fa, _, _, _ = net.emb(vx)\n",
    "        fake = net.decode(fa, False)\n",
    "        return ((fake + 1) / 2).clamp_(0,1)\n",
    "\n",
    "def display_recon(g=iter(md.val_dl),bs=params[\"bs\"]//2):\n",
    "    x, _ = next(g)\n",
    "    vx = V(x[:bs])\n",
    "    z_im, _, _ = net(vx)\n",
    "    z_im = z_im.data.cpu().numpy().reshape(-1,28,28)*255.\n",
    "    fig, axes = plt.subplots(2, bs, figsize=(15,3))\n",
    "    for ax, im in enumerate(x[:bs]):\n",
    "        axes[0,ax].imshow(im[0,:,:])\n",
    "        axes[1,ax].imshow(z_im[ax])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def display_gen(bs=params[\"bs\"], mode=0):\n",
    "    if mode == 0:\n",
    "        ims,_,_ = generate(bs, mode)\n",
    "    else:\n",
    "        ims = generate(bs, mode)\n",
    "    ims = ims.data.cpu().numpy()\n",
    "    ims = ims.reshape(-1,28,28)*255.\n",
    "    plt.figure(figsize=(15,3))\n",
    "    for i, im in enumerate(ims):\n",
    "        plt.subplot(2,bs/2,i+1)\n",
    "        plt.imshow(im)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.vae = True\n",
    "display_recon(g); display_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_recon(g); display_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
